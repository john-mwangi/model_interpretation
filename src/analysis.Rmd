---
title: 'Oral Prep: Model interpretation'
output: html_document
author: "John Mwangi"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# PACKAGES

```{r message=FALSE, warning=FALSE}
rm(list = ls())

#library(iml)
library(factoextra)
library(pdp)
library(caret)
library(expss)
library(writexl)
library(readxl)
library(corrr)
library(rlang)
library(tidyverse)
```

Constants.

```{r}
ROUND <- 2
```

# DATA IMPORTATION

```{r}
data_sav <-
  haven::read_sav(file = "../inputs/Source Data/Oral PrEP  survey v5_WIDE.sav") %>%
  map_df(.f = ~expss::na_if(x = ., value = "", with_labels = TRUE))

data_dictionary <- create_dictionary(x = data_sav)

data_raw <-
  read_excel("../inputs/Behavioural Scoring/Clean_data_scored1_3Clusters_v2.xlsx", 
             na = "NA") %>% 
  select(-1)


data_sav
data_dictionary
data_raw
```

## Validate

Validate that the segments I have are the same as what's in the report.

I recommended 3 segments per population but the report contains 2 segments per population. This work was likely done by Peter prior to me getting involved. We will focus only on the behavioral scores since my involvement was from there.

```{r}
data_raw %>% 
  group_by(Population, b_segment) %>% 
  summarise(age = median(clean_age, na.rm = TRUE))
```

This is the work that Peter had done. It shows that FSW had 4 segments but the report has 2 segments.

```{r}
data_pk <- readRDS(file = "../inputs/Source Data/Segments_PK.rds")

data_pk %>% 
  group_by(Population, Segment) %>% 
  summarise(age = mean(clean_age, na.rm = TRUE))
```

## Add data labels

```{r}
surv_cols <- tibble(surv_cols = data_raw %>% colnames())

surv_cols
data_dictionary
```


```{r}
surv_cols <-
surv_cols %>% 
  mutate(variable = str_extract(string = surv_cols, 
                                pattern = "q.*$")) %>% 
  mutate(variable = coalesce(variable, surv_cols))

surv_cols
```

Retrieve data labels.

Behaviour labels.

```{r}
behave_vars <- read_excel(path = "../inputs/Source Data/behave_labels.xlsx")

behave_vars <-
behave_vars %>% 
  rename(surv_cols = variable)

behave_vars
```


```{r}
surv_labels <-
surv_cols %>% 
  left_join(data_dictionary, by = "variable") %>% 
  group_by(surv_cols) %>% 
  slice(1) %>% 
  ungroup() %>% 
  left_join(behave_vars, by = "surv_cols") %>% 
  mutate(label = coalesce(label.x, label.y)) %>% 
  select(surv_cols, variable, label)

surv_labels %>% filter(!is.na(label))
```


## Add labels to raw_data

```{r}
data_labeled <- tibble(.rows = 597)

for (i in seq_along(colnames(data_raw))){
  labeled_col <- set_var_lab(x = data_raw %>% select(i), value = surv_labels$label[i])
  data_labeled <- bind_cols(data_labeled, labeled_col)
}

data_labeled
```

## Clarifications

Why is this question is repeated severally? These seem to be the same questions in a randomised order.

```{r}
data_proc %>% 
  select(contains("q117"))
```

What do these numbers mean? This is a bean game. The second question is a counterfactual to the first one.

```{r}
data_proc %>% 
  select(contains("q147"))
```


## Identifying questions 

Questions ending with `_[0-9]{,2}` are subquestions.

```{r}
sub_questions <- 
  grepl(pattern = "_\\d+$", 
        x = colnames(data_proc), 
        ignore.case = TRUE)

length(sub_questions)
```

```{r}
questions <- colnames(data_proc)[!sub_questions]

data_questions <- data_proc %>% select(questions)

data_questions
```

# BEHAVIORAL SCORING

Because the segments that are in the report are different from what Peter or I did, we will focus analysis on behavioral scoring but not bring in segment conversation until we have the final segments that are in the report.

## Process overview

* Data preparation (variable selection)
* Predict continuation rates
* Evaluate accuracy of prediction of continuation rates
* Calculate behavioural score

## Data preparation

Importation

```{r}
load("../inputs/Behavioural Scoring/b_score_model.RData")

dim(df)
```

Removed variables with NAs

```{r}
sum(colSums(is.na(df))>0)

sum(colSums(is.na(df))==0)
```

Removed screeners, identifiers, survey running totals, survey calculations

```{r}
id_cols <- c("SubmissionDate","starttime","endtime","deviceid","enum","cal222","calc233","metainstanceID","formdef_version","KEY","SubmissionDate2","pasted","pasted2","df","Age","q13","e1end11e2Cons_rand_calc_1","e1end11e2Cons_rand_calc_2","e1end11e2calc_3","q16","e1end11e2bean_bean1calc_bean","e1end11e2bean_bean2calc_bean2","e1end11e2bean_bean3calc_bean3","e1end11e2bean_bean4calc_bean4","e1end11e2bean_bean5calc_bean5","e1demoq9","e1end11e2bean_bean6calc_bean6","e1end11e2calc_4","cal888","Continuation_rates_dummy","e1demoq12","e1demoend1cp","Client_ID","e1end11e2bean_bean1q146b","e1end11e2bean_bean2q147b","e1end11e2bean_bean3q148b","e1end11e2bean_bean4q149b","e1end11e2bean_bean6q151b")

length(unique(id_cols))
```

Removed constant columns

```{r}
length(Near_zero)
```

Categorical variables with too many levels - None were identified.

```{r}
data.frame(catvar_type) %>% 
  count(X2) %>% 
  mutate(X2 = as.numeric(X2)) %>% 
  arrange(-X2)
```

Removed multi-collinear variables - None were identified.

```{r}
library(corrr)

num_vars %>% 
  correlate() %>% 
  shave() %>% 
  pivot_longer(cols = -term,
               names_to = "variable",
               values_to = "correlation") %>% 
  arrange(desc(correlation))
```

```{r}
dim(final_clean)
```


## Which model was used?

A random forest with 28 predictors was used.

```{r}
model_rf_wr
```

## How did we select the 28 variables?

```{r}
model_rf_2
```

There is a sudden steep drop in important after variable number 28.

```{r}
varImp(object = model_rf_2)$importance %>% 
  rownames_to_column("variable") %>% 
  arrange(desc(Overall)) %>% 
  left_join(surv_labels, by = c("variable"="surv_cols")) %>% 
  select(variable, Overall, label)
#  write_xlsx(path = "../outputs/var_imp.xlsx")
```

## Variable importance

```{r}
varImp(object = model_rf_2)$importance %>% 
  arrange(desc(Overall)) %>% 
  head(35) %>% 
  rownames_to_column("variable") %>% 
  mutate(variable = fct_reorder(variable, Overall)) %>% 
  ggplot(aes(x = variable, y = Overall)) +
  geom_col() +
  coord_flip() +
  labs(title = "Variable importance plot",
       subtitle = "28 most important variables in the Random Forest",
       x = NULL) +
  geom_vline(xintercept = "little_chance", lty = 2)
```

## How accurate was the behavioural scoring model?

Confusion matrix.

```{r}
pred_classes <- predict(object = model_rf_wr, newdata = final_clean, type = "raw")
pred_probs <- predict(object = model_rf_wr, newdata = final_clean, type = "prob")
```


```{r}
identical(as.character(final_clean$Population), data_raw$Population)
```

The model was 100% accurate on the test set. **In terms of assigning behavioural scores to survey participants, these are the scores that were assigned** hence these results are still useful. However, a validation set was introduced when it can to deploying the predictive tool. **The deployed model will also be evaluated on its own and these two results tied together.**

```{r}
confusionMatrix(data = pred_classes, reference = final_clean$Continuation_rates)
```

## Behavioural scores per population


```{r}
b_scores <-
pred_probs %>% 
  mutate(b_score = Continuation.3 + Continuation.2,
         b_score = round(b_score*1000)) %>% 
  pull(b_score)

b_scores[1:10]
```


```{r}
bscore_summaries <-
data_raw %>% 
  mutate(b_score = b_scores) %>% 
  select(Population, b_score) %>% 
  group_by(Population) %>%
  summarise(min_score = min(b_score),
            mean_score = mean(b_score),
            max_score = max(b_score),
            median_score = median(b_score),
            pop = n()) %>% 
  arrange(mean_score)

bscore_summaries
#bscore_summaries %>% write_xlsx("../outputs/bscore_summaries.xlsx")

bscore_summaries %>% 
  mutate(Population = fct_reorder(Population, mean_score)) %>% 
  ggplot(aes(x = Population, y = mean_score)) +
  geom_col() +
  geom_hline(yintercept = 500, lty = 2) +
  geom_errorbar(aes(ymin = min_score, ymax = max_score), width = 0.2) +
  geom_text(aes(label = min_score, y = min_score), vjust = 1) +
  geom_text(aes(label = max_score, y = max_score), vjust = -0.5) +
  geom_text(aes(label = round(mean_score), y = mean_score)) +
  labs(title = "Summary of behavioural scores",
       subtitle = "Indicating the mean, max, and min scores",
       x = NULL,
       y = "Behavioural score")
```

## Segments

Each population was split into 2 clusters per population.

```{r}
# Formular to replicate
cutree(tree = hclust(d = dist(x = b_scores, method = "euclidean"), method = "ward.D2"), 
       k = 2)[1:20]
```

Create a nested tibble containing the results of the segmentation (tree, segments). Segments are on page 43 of the report.

```{r}
pop_segments <-
data_raw %>% 
  select(Client_ID,Population) %>% 
  mutate(b_score = b_scores) %>% 
  group_by(Population) %>% 
  nest() %>% 
  mutate(tree = map(.x = data, 
                    .f = ~hclust(d = dist(x = .$b_score, 
                                          method = "euclidean"), 
                                 method = "ward.D2"))) %>% 
  bind_cols(k = c(3,4,3)) %>% 
  mutate(segments = map2(.x = tree, 
                         .y = k, 
                         .f = ~cutree(tree = .x, k = .y))) %>% 
  mutate(data = map(.x = data, 
                    .f = ~mutate(.data = ., segment = segments[[1]]))) %>% 
  ungroup()

pop_segments
```

```{r}
pop_segments %>% 
  filter(str_detect(string = Population, pattern = "FSWs")) %>% 
  pull(segments)
```


## Behavioural scores per segment

Some summary statistics of the segmentation.

```{r}
segment_data <- tibble(.rows = 0)

for (p in seq_along(pop_segments$Population)){

pop_scores <-
pop_segments$data[[p]] %>% 
  mutate(segment = as.character(segment)) %>% 
  mutate(population = pop_segments$Population[p])

segment_data <- rbind(segment_data, pop_scores)
}

segment_data
```


```{r}
b_scores_segment <-
segment_data %>% 
  group_by(population, segment) %>% 
  summarise(mean_score = round(mean(b_score)),
            min_score = min(b_score),
            max_score = max(b_score),
            size = n())

b_scores_segment
#b_scores_segment %>% write_xlsx("../outputs/b_scores_segment.xlsx")
```


```{r}
b_scores_segment %>% 
  ggplot(aes(x = segment, y = mean_score)) +
  geom_col() +
  geom_hline(yintercept = 500, lty = 2) +
  facet_wrap(~population, scales = "free_x") +
  geom_errorbar(aes(ymin = min_score, ymax = max_score), width = 0.2) +
  geom_text(aes(label = glue::glue("{mean_score}({size})"), y = mean_score)) +
  #geom_text(aes(label = mean_score, y = mean_score), nudge_x = -0.25) +
  labs(title = "Behavioural scores per segment",
       y = "Behavioural score")
```

## Appropriate number of segments

### Dendrogram

Considerations why 2 segments were used instead of 3:
* Size segments are smaller making analysis less effective
* Rolling out effective campaigns with 9 segments is more challenging

```{r}
plot(pop_segments$tree[[1]], main = "Dendrogram for AGYW")
abline(h = 300, col = "red")
```

### Cluster Visualisation

```{r}

silhoutte <- list()

for (pop in seq_along(pop_segments$data)){

silhoutte[[pop]] <- fviz_nbclust(
  x = data.frame(b_scores = pop_segments$data[[pop]]$b_score), 
  FUNcluster = hcut, 
  method = "silhouette")

silhoutte[[pop]] <-
silhoutte[[pop]] + 
  labs(title = glue::glue("Optimal number of clusters in {pop_segments$Population[[pop]]}"))
}


for (pop in 1:pop){
  print(silhoutte[[pop]])
}
```


```{r}

gap_stat <- list()

for (pop in seq_along(pop_segments$data)){

gap_stat[[pop]] <- fviz_nbclust(
  x = data.frame(b_scores = pop_segments$data[[pop]]$b_score), 
  FUNcluster = hcut, 
  method = "gap_stat", 
  nboot = 10)

gap_stat[[pop]] <-
gap_stat[[pop]] + 
  labs(title = glue::glue("Optimal number of clusters in {pop_segments$Population[[pop]]}"))
}


for (pop in 1:pop){
  print(gap_stat[[pop]])
}
```


## Comparision with previous segments

```{r}
data_pk %>% 
  select(Client_ID, previous_segment = Segment, Continuation_rates = Continuation_rates.x) %>% 
  left_join(segment_data, by = "Client_ID") %>% 
  rename(current_segment = segment) %>% 
  mutate(previous_segment = parse_number(previous_segment)) %>% 
  mutate(previous_segment = as.character(previous_segment)) %>% 
  group_by(population, previous_segment) %>% 
  mutate(previous_count = n()) %>% 
  group_by(population, current_segment) %>% 
  mutate(current_count = n()) %>% 
  group_by(population, Continuation_rates, previous_segment, current_segment) %>% 
  summarise(previous_count = mean(previous_count),
            current_count = mean(current_count)) %>% 
  ungroup() %>% 
  relocate(previous_count, .after = previous_segment) %>% 
  write_xlsx("../outputs/segment_comparison.xlsx")
```


```{r}
data_pk %>% 
  select(Client_ID, previous_segment = Segment, Continuation_rates = Continuation_rates.x) %>% 
  left_join(segment_data, by = "Client_ID") %>% 
  rename(current_segment = segment) %>% 
  mutate(previous_segment = parse_number(previous_segment)) %>% 
  mutate(previous_segment = as.character(previous_segment)) %>% 
  filter(str_detect(string = population, pattern = "FSW")) %>% 
  count(previous_segment, current_segment) %>% 
  filter(previous_segment %in% c(1, 4))
```


## SHAP values

**This approach was not used as the results were not easy to interpret especially for continuous variables.**

Useful for understanding the direction of influence of features

```{r}
data_train <- final_clean[,names(final_clean) %in% c(imp_vars_wrapper,"Continuation_rates")]
data_train <- cbind(data_train, b_score = data_raw$b_score/1000)

data_train_x <- data_train %>% select(-Continuation_rates, -b_score)

data_train_lo <- data_train %>% filter(Continuation_rates=="No.continuation") %>% select(-Continuation_rates, -b_score)

data_train_hi <- data_train %>% filter(Continuation_rates=="Continuation.3") %>% select(-Continuation_rates, -b_score)
```


```{r}
# :class: name of the class we are interested in. Leave blank to get all classes

shap_predictor <-
Predictor$new(model = model_rf_wr,
              data = data_train %>% select(-b_score),
              y = "Continuation_rates",
              class = c("No.continuation"),
              type = "prob")

shap_predictor
```


```{r}
system.time({

doParallel::registerDoParallel(cores = parallel::detectCores())

# shap_res_low <-
# Shapley$new(predictor = shap_predictor, 
#             x.interest = data_train_lo,
#             sample.size = 5)

shap_res_low <-
Shapley$new(predictor = shap_predictor, 
            x.interest = data_train_lo,
            sample.size = 50)

shap_res_high <-
Shapley$new(predictor = shap_predictor, 
            x.interest = data_train_hi,
            sample.size = 50)

doParallel::stopImplicitCluster()

})
```

What does Age=24 or Age=18 mean?

```{r}
library(patchwork)

plot_low <- plot(shap_res_low)
plot_high <- plot(shap_res_high)

plot_low
plot_high
```



```{r}
library(tidytext)

shap_res$results %>% 
  mutate(feature.value = reorder_within(feature.value, phi, class)) %>% 
  ggplot(aes(x = feature.value, y = abs(phi))) +
  geom_col() +
  coord_flip() +
  facet_wrap(~class, "free") +
  scale_x_reordered()
```

## PDP plots

### Variables list

Define a nested list of variables and their class.

```{r}
model_vars <-
final_clean %>% 
  select(all_of(imp_vars_wrapper)) %>% 
  summarise(across(.cols = everything(), .fns = class)) %>% 
  pivot_longer(cols = everything(),
               names_to = "variable",
               values_to = "class") %>% 
  mutate(vars = map2(.x = variable, .y = class, .f = list)) %>% 
  pull(vars)

length(model_vars)
```


```{r}
model_vars[1]

model_vars[[1]][1]

unlist(model_vars[[1]][2])

class(unlist(model_vars[[1]][2]))

unlist(model_vars[[1]][2])=="factor"
```

### Plotting function

This will return just one plot for a given to be stored in a list later.

```{r}
# model: a trained model
# continuation rate: a outcome in the outcome variable
# model vars: a nested list containing an independent variable and its class
# returns: a named list containing a single plot, its table, and continuation rate being observed

plot_pdp <- function(model, continuation_rate, model_vars){
  
  variable <- unlist(model_vars[[1]][1])
  class <- unlist(model_vars[[1]][2])
  
  if (class == "factor"){
    
    pdp_plot <-
    pdp::partial(object = {{ model }},
            pred.var = variable,
            which.class = continuation_rate,
            plot = FALSE,
            plot.engine = "ggplot2") %>%
    as_tibble() %>%
    mutate({{ variable}} := fct_reorder(.data[[variable]], yhat)) %>%
    ggplot(aes(x = .data[[variable]], y = yhat)) +
    geom_col() +
    coord_flip() +
    labs(title = glue::glue("PDP for {variable} on {continuation_rate}"),
         x = NULL)

  } else {

  pdp_plot <-
  pdp::partial(object = {{ model }},
          pred.var = variable,
          which.class = continuation_rate,
          plot = TRUE,
          plot.engine = "ggplot2") +
  geom_smooth(method = "loess", se = TRUE, formula = y ~ x) +
  labs(title = glue::glue("PDP for {variable} on {continuation_rate}"))

  }
  
  pdp_tbl <-
    pdp::partial(object = {{ model }},
            pred.var = variable,
            which.class = continuation_rate,
            plot = FALSE,
            plot.engine = "ggplot2") %>%
    as_tibble() %>% 
    mutate({{ variable}} := as.character(.data[[variable]]))


  pdp_plots <- list(plt = pdp_plot,
                    tbl = pdp_tbl,
                    rate = continuation_rate)
  
  return(pdp_plots)
}
```


```{r}
pdp_plots <- plot_pdp(model = model_rf_wr, continuation_rate = "No.continuation", model_vars = model_vars[2])

pdp_plots$plt

pdp_plots$tbl

pdp_plots$rate
```


### Obtain PDP results

This will take the returned named list and store it in a list.

```{r}
doParallel::registerDoParallel(cores = 2)

pdp_res <- list()

for (var in seq_along(model_vars)){
pdp_res[[var]] <- plot_pdp(model = model_rf_wr,
                           continuation_rate = "No.continuation",
                           model_vars = model_vars[var])
}

doParallel::stopImplicitCluster()

length(pdp_res)
```


### Print plots

Iterate over the list of results and print each plot.

```{r}
doParallel::registerDoParallel(cores = parallel::detectCores())

for (res in seq_along(pdp_res)){
  suppressWarnings(print(pdp_res[[res]]$plt))
}

doParallel::stopImplicitCluster()
```


### Print both tables and plots

```{r}
doParallel::registerDoParallel(cores = parallel::detectCores())

for (res in seq_along(pdp_res[1:2])){
  suppressWarnings(print(pdp_res[[res]]))
}

doParallel::stopImplicitCluster()
```


### Concatenated tables

```{r}
pdp_tbls <- tibble(.rows = 0)

for (var in seq_along(pdp_res)){
  pdp_df <- 
    pdp_res[[var]]$tbl %>% 
    mutate(variable = colnames(.)[1]) %>% 
    mutate(rate = pdp_res[[var]]$rate) %>% 
    setNames(object = ., nm = c("response","yhat","variable","continuation_rate"))
  
  pdp_tbls <- rbind(pdp_tbls, pdp_df)
}

pdp_tbls
```

```{r}
write_xlsx(pdp_tbls,"../outputs/pdp_res_tbl_no.xlsx")
```

## Sense checks

* Older people are in Continuation 3, younger people in Continuation 1
* People in Migori & Nyamari are likely to be in No continuation category

```{r}
data_train %>% 
  group_by(Continuation_rates) %>% 
  summarise(age = mean(clean_age))

data_train %>% 
  group_by(Continuation_rates, Clinic) %>% 
  summarise(n = n()) %>%
  arrange(Continuation_rates, desc(n))
```


# SUMMARY STATISTICS

Summary and descriptive statistics of the 28 most important variables.

## Categorical variables

Counts of responses per segment.

```{r}
cat_cols <- 
data_raw %>% 
  select(imp_vars_wrapper) %>% 
  select(is_character) %>% 
  colnames()

cat_cols
```

```{r}
segmented_obs <-
data_raw %>% 
  select(c("Client_ID", imp_vars_wrapper)) %>% 
  left_join(segment_data, by = "Client_ID") %>% 
  select(-Client_ID) %>% 
  group_by(population, segment)

segmented_obs
```


```{r}
count_df <- tibble(.rows = 0)

for (col in seq_along(cat_cols)){
df <-
  segmented_obs %>% 
  count(response = .data[[cat_cols[col]]]) %>% 
  mutate(variable = cat_cols[col])

count_df <- rbind(count_df, df)
}

count_df

#write_xlsx(x = count_df, path = "../outputs/count_df.xlsx")
```

## Numeric varibles

Mean and median values

```{r}
means_df <-
segmented_obs %>% 
  select(is.numeric) %>% 
  select(-b_score) %>% 
  summarise(across(.cols = everything(), 
                   .fns = list(mean = mean, 
                               median = median))) %>% 
  pivot_longer(cols = c(-population, -segment)) %>% 
  extract(col = name, 
          into = c("variable","metric"), 
          regex = "(.*)_(.*)", 
          remove = TRUE) %>% 
  pivot_wider(names_from = metric,
              values_from = value) %>% 
  mutate(mean = round(mean, 1))

means_df

#write_xlsx(x = means_df, path = "../outputs/means_df.xlsx")
```


```{r}
data_raw %>% 
  mutate(Continuation_rates = factor(Continuation_rates)) %>% 
  mutate(Continuation_rates = relevel(x = Continuation_rates, ref = "No continuation")) %>% 
  ggplot(aes(Continuation_rates)) +
  geom_histogram(stat = "count")
```


# EXPORT

```{r}
save.image("../outputs/24July.RData")

load("../outputs/21July.RData")
```



