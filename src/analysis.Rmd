---
title: 'Oral Prep: Model interpretation'
output: html_document
author: "John Mwangi"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# PACKAGES

```{r message=FALSE, warning=FALSE}

#library(iml)
library(scales)
library(glue)
library(factoextra)
library(pdp)
library(caret)
library(expss)
library(writexl)
library(readxl)
library(corrr)
library(rlang)
library(tidyverse)
```

Constants.

```{r}
ROUND <- 1
```

# DATA IMPORTATION

## Import

```{r}
data_sav <-
  haven::read_sav(file = "../inputs/Source Data/Oral PrEP  survey v5_WIDE.sav") %>%
  map_df(.f = ~expss::na_if(x = ., value = "", with_labels = TRUE))

data_raw <-
  read_excel("../inputs/Behavioural Scoring/Clean_data_scored1_3Clusters_v2.xlsx", 
             na = "NA") %>% 
  select(-1)


data_sav
data_raw
```

## Validate

Validate that the segments I have are the same as what's in the report.

I recommended 3 segments per population but the report contains 2 segments per population. This work was likely done by Peter prior to me getting involved. We will focus only on the behavioral scores since my involvement was from there.

```{r}
data_raw %>% 
  group_by(Population, b_segment) %>% 
  summarise(age = median(clean_age, na.rm = TRUE))
```

This is the work that Peter had done. It shows that FSW had 4 segments but the report has 2 segments.

```{r}
data_pk <- readRDS(file = "../inputs/Source Data/Segments_PK.rds")

data_pk %>% 
  group_by(Population, Segment) %>% 
  summarise(age = mean(clean_age, na.rm = TRUE))
```

## Add data labels

Import survey instrument variable names and labels

```{r}
cto_spec <-
  read_excel(path = "../inputs/Source Data/Oral PrEP 15102019_GM0.xlsx", sheet = "survey") %>% 
  select(type, name, label) %>% 
  filter(!is.na(name))

cto_spec
```

Labels for Bahavioural questions.

```{r}
behave_vars <- read_excel(path = "../inputs/Source Data/behave_labels.xlsx")
```

Add labels from the survey instrument.

```{r}
raw_labels <-
data_raw %>% 
  colnames() %>% 
  as_tibble() %>% 
  mutate(name = str_extract(string = value, pattern = "q.*$")) %>% 
  mutate(name = coalesce(name, value)) %>% 
  mutate(main = str_extract(string = name, pattern = "^q\\d+_")) %>% 
  mutate(main = str_remove(string = main, pattern = "_")) %>% 
  mutate(main = coalesce(main, name)) %>% 
  left_join(cto_spec, by = c("main" = "name")) %>% 
  left_join(behave_vars, by = c("name"="variable")) %>% 
  mutate(label = coalesce(label.x, label.y)) %>% 
  select(-label.x, -label.y)

raw_labels
```


## Add labels to raw_data

```{r}
data_labeled <- tibble(.rows = nrow(data_raw))

for (i in seq_along(colnames(data_raw))){
  labeled_col <- set_var_lab(x = data_raw %>% select(i), value = raw_labels$label[i])
  data_labeled <- bind_cols(data_labeled, labeled_col)
}

data_labeled
```

## Add value labels

Convert values to label for `e1end11e2hseq32`

```{r}
data_sav$q32

data_labeled <-
data_labeled %>% 
  mutate(e1end11e2hseq32 = set_val_lab(x = data_labeled$e1end11e2hseq32, value = val_lab(data_sav$q32), add = TRUE)) %>% 
  mutate(e1end11e2hseq32 = values2labels(e1end11e2hseq32))

data_labeled
```


## Relabel some variables

Variables to re-label

```{r}
re_label <-
cto_spec %>% 
  filter(str_detect(string = name, pattern = "\\.")) %>% 
  mutate(rename = glue::glue("e1demoend1{name}"))

re_label
```


```{r}
to_relabel <- data_labeled %>% select(e1demoend1q26:e1demoend1q28b)

relabeled <- tibble(.rows = nrow(data_raw))

for (r in seq_along(colnames(to_relabel))){
  labeled_col <- set_var_lab(x = to_relabel %>% select(r), value = re_label$label[[r]])
  relabeled <- bind_cols(relabeled, labeled_col)
}

relabeled <- set_names(x = relabeled, nm = re_label$rename)

relabeled
```


```{r}
data_labeled <-
data_labeled %>% 
  select(-all_of(colnames(to_relabel))) %>% 
  bind_cols(relabeled)

data_labeled
```

## Data dictionary

```{r}
data_dictionary <- create_dictionary(x = data_labeled)

data_dictionary
#write_xlsx(x = data_dictionary, path = "../outputs/data_dictionary.xlsx")

data_dictionary_updated <- read_excel(path = "../../Dashboard/data_dictionary_updated.xlsx")

data_dictionary_updated
```


## e1q8

Check if this variable is a replica of the outcome variable. 

Answer: No

```{r}
data_raw %>% 
  select(Continuation_rates, e1q8) %>% 
  group_by(Continuation_rates) %>% 
  summarise(range = range(e1q8))
```


```{r}
data_raw %>% 
  select(Continuation_rates, e1q8) %>% 
  group_by(Continuation_rates) %>% 
  ggplot(aes(x = e1q8)) +
  geom_histogram(bins = 10) +
  facet_wrap(~Continuation_rates)
```

## Clarifications

Why is this question is repeated severally? These seem to be the same questions in a randomised order.

```{r}
data_proc %>% 
  select(contains("q117"))
```

What do these numbers mean? This is a bean game. The second question is a counterfactual to the first one.

```{r}
data_proc %>% 
  select(contains("q147"))
```


## Identifying questions 

Questions ending with `_[0-9]{,2}` are subquestions.

```{r}
sub_questions <- 
  grepl(pattern = "_\\d+$", 
        x = colnames(data_proc), 
        ignore.case = TRUE)

length(sub_questions)
```

```{r}
questions <- colnames(data_proc)[!sub_questions]

data_questions <- data_proc %>% select(questions)

data_questions
```


## Multiple select questions

Apart from q40, most multiple select questions contain NA values.

```{r}
data_sav %>% 
  select(contains("q40"))

data_raw %>% 
  select(contains("q40")) %>% 
  count(e1end11e2prepq40_1)
```

## Numeric demograpic variables

These variables are captured as character but should be numeric.

```{r}
data_labeled <-
data_labeled %>% 
  mutate(across(.cols = c("e1demoend1q21","e1end11e2hseq25",
                          "e1end11e2hseq29","e1end11e2hseq29b",
                          "e1end11e2hseq30","e1end11e2hseq31"), 
                .fns = as.numeric))

data_labeled
```


```{r}
data_labeled %>% 
  select(where(is.numeric)) %>% 
  colnames()
```

## Shorten population

```{r}
data_labeled <-
data_labeled %>% 
  mutate(Population = str_squish(Population)) %>% 
  mutate(Population = case_when(Population == "Female Sex Workers (FSWs)" ~ "FSWs",
                                Population == "Men who have sex with Men (MSMs)" ~ "MSMs",
                                TRUE ~ "AGYWs"))

data_labeled
```

## Fix incorrect categories

```{r}
data_labeled <-
data_labeled %>% 
  mutate(e1end11e2hseq32 = str_replace(string = e1end11e2hseq32, 
                                       pattern = "4", 
                                       replacement = "Undecided/ Donâ€™t know"))

unique(data_labeled$e1end11e2hseq32)

data_labeled
```

## Likert variables

Change Likert scale variables to categorical variables. This is for purposes of summary statistics.

```{r}
data_labeled <-
data_labeled %>%
  mutate(across(.cols = behave_vars$variable,
                .fns = as.character))

data_labeled
```


# BEHAVIORAL SCORING

Because the segments that are in the report are different from what Peter or I did, we will focus analysis on behavioral scoring but not bring in segment conversation until we have the final segments that are in the report.

## Process overview

* Data preparation (variable selection)
* Predict continuation rates
* Evaluate accuracy of prediction of continuation rates
* Calculate behavioural score

## Data preparation

Importation

```{r}
load("../inputs/Behavioural Scoring/b_score_model.RData")

dim(df)
```

Removed variables with NAs

```{r}
sum(colSums(is.na(df))>0)

sum(colSums(is.na(df))==0)
```

Removed screeners, identifiers, survey running totals, survey calculations

```{r}
id_cols <- c("SubmissionDate","starttime","endtime","deviceid","enum","cal222","calc233","metainstanceID","formdef_version","KEY","SubmissionDate2","pasted","pasted2","df","Age","q13","e1end11e2Cons_rand_calc_1","e1end11e2Cons_rand_calc_2","e1end11e2calc_3","q16","e1end11e2bean_bean1calc_bean","e1end11e2bean_bean2calc_bean2","e1end11e2bean_bean3calc_bean3","e1end11e2bean_bean4calc_bean4","e1end11e2bean_bean5calc_bean5","e1demoq9","e1end11e2bean_bean6calc_bean6","e1end11e2calc_4","cal888","Continuation_rates_dummy","e1demoq12","e1demoend1cp","Client_ID","e1end11e2bean_bean1q146b","e1end11e2bean_bean2q147b","e1end11e2bean_bean3q148b","e1end11e2bean_bean4q149b","e1end11e2bean_bean6q151b")

length(unique(id_cols))
```

Removed constant columns

```{r}
length(Near_zero)
```

Categorical variables with too many levels - None were identified.

```{r}
data.frame(catvar_type) %>% 
  count(X2) %>% 
  mutate(X2 = as.numeric(X2)) %>% 
  arrange(-X2)
```

Removed multi-collinear variables - None were identified.

```{r}
library(corrr)

num_vars %>% 
  correlate() %>% 
  shave() %>% 
  pivot_longer(cols = -term,
               names_to = "variable",
               values_to = "correlation") %>% 
  arrange(desc(correlation))
```

```{r}
dim(final_clean)
```


## Which model was used?

A random forest with 28 predictors was used.

```{r}
model_rf_wr
```

## How did we select the 28 variables?

```{r}
model_rf_2
```

There is a sudden steep drop in important after variable number 28.

```{r}
varImp(object = model_rf_2)$importance %>% 
  rownames_to_column("variable") %>% 
  arrange(desc(Overall)) %>% 
  left_join(surv_labels, by = c("variable"="surv_cols")) %>% 
  select(variable, Overall, label)
#  write_xlsx(path = "../outputs/var_imp.xlsx")
```

## Variable importance

```{r}
varImp(object = model_rf_2)$importance %>% 
  arrange(desc(Overall)) %>% 
  head(35) %>% 
  rownames_to_column("variable") %>% 
  mutate(variable = fct_reorder(variable, Overall)) %>% 
  ggplot(aes(x = variable, y = Overall)) +
  geom_col() +
  coord_flip() +
  labs(title = "Variable importance plot",
       subtitle = "28 most important variables in the Random Forest",
       x = NULL) +
  geom_vline(xintercept = "little_chance", lty = 2)
```

## How accurate was the behavioural scoring model?

Confusion matrix.

```{r}
pred_classes <- predict(object = model_rf_wr, newdata = final_clean, type = "raw")
pred_probs <- predict(object = model_rf_wr, newdata = final_clean, type = "prob")
```


```{r}
identical(as.character(final_clean$Population), data_raw$Population)
```

The model was 100% accurate on the test set. **In terms of assigning behavioural scores to survey participants, these are the scores that were assigned** hence these results are still useful. However, a validation set was introduced when it can to deploying the predictive tool. **The deployed model will also be evaluated on its own and these two results tied together.**

```{r}
confusionMatrix(data = pred_classes, reference = final_clean$Continuation_rates)
```

## Behavioural scores per population


```{r}
b_scores <-
pred_probs %>% 
  mutate(b_score = Continuation.3 + Continuation.2,
         b_score = round(b_score*1000)) %>% 
  pull(b_score)

b_scores[1:10]
```


```{r}
bscore_summaries <-
data_raw %>% 
  mutate(b_score = b_scores) %>% 
  select(Population, b_score) %>% 
  group_by(Population) %>%
  summarise(min_score = min(b_score),
            mean_score = mean(b_score),
            max_score = max(b_score),
            median_score = median(b_score),
            pop = n()) %>% 
  arrange(mean_score)

bscore_summaries
#bscore_summaries %>% write_xlsx("../outputs/bscore_summaries.xlsx")

bscore_summaries %>% 
  mutate(Population = fct_reorder(Population, mean_score)) %>% 
  ggplot(aes(x = Population, y = mean_score)) +
  geom_col() +
  geom_hline(yintercept = 500, lty = 2) +
  geom_errorbar(aes(ymin = min_score, ymax = max_score), width = 0.2) +
  geom_text(aes(label = min_score, y = min_score), vjust = 1) +
  geom_text(aes(label = max_score, y = max_score), vjust = -0.5) +
  geom_text(aes(label = round(mean_score), y = mean_score)) +
  labs(title = "Summary of behavioural scores",
       subtitle = "Indicating the mean, max, and min scores",
       x = NULL,
       y = "Behavioural score")
```

## Segments

Each population was split into 2 clusters per population.

```{r}
# Formular to replicate
cutree(tree = hclust(d = dist(x = b_scores, method = "euclidean"), method = "ward.D2"), 
       k = 2)[1:20]
```

Create a nested tibble containing the results of the segmentation (tree, segments). Segments are on page 43 of the report.

```{r}
pop_segments <-
data_raw %>% 
  select(Client_ID,Population) %>% 
  mutate(b_score = b_scores) %>% 
  group_by(Population) %>% 
  nest() %>% 
  mutate(tree = map(.x = data, 
                    .f = ~hclust(d = dist(x = .$b_score, 
                                          method = "euclidean"), 
                                 method = "ward.D2"))) %>% 
  bind_cols(k = c(2,2,2)) %>% 
  mutate(segments = map2(.x = tree, 
                         .y = k, 
                         .f = ~cutree(tree = .x, k = .y))) %>% 
  mutate(data = map(.x = data, 
                    .f = ~mutate(.data = ., segment = segments[[1]]))) %>% 
  ungroup()

pop_segments
```

```{r}
pop_segments %>% 
  filter(str_detect(string = Population, pattern = "FSWs")) %>% 
  pull(segments)
```


## Behavioural scores per segment

Some summary statistics of the segmentation.

```{r}
segment_data <- tibble(.rows = 0)

for (p in seq_along(pop_segments$Population)){

pop_scores <-
pop_segments$data[[p]] %>% 
  mutate(segment = as.character(segment)) %>% 
  mutate(population = pop_segments$Population[p])

segment_data <- rbind(segment_data, pop_scores)
}

segment_data
```


```{r}
b_scores_segment <-
segment_data %>% 
  group_by(population, segment) %>% 
  summarise(mean_score = round(mean(b_score)),
            min_score = min(b_score),
            max_score = max(b_score),
            size = n())

b_scores_segment

#b_scores_segment %>% write_xlsx("../outputs/b_scores_segment.xlsx")
```


```{r}
b_scores_segment %>% 
  ggplot(aes(x = segment, y = mean_score)) +
  geom_col() +
  geom_hline(yintercept = 500, lty = 2) +
  facet_wrap(~population, scales = "free_x") +
  geom_errorbar(aes(ymin = min_score, ymax = max_score), width = 0.2) +
  geom_text(aes(label = glue::glue("{mean_score}({size})"), y = mean_score)) +
  #geom_text(aes(label = mean_score, y = mean_score), nudge_x = -0.25) +
  labs(title = "Behavioural scores per segment",
       y = "Behavioural score")
```

## Appropriate number of segments

### Dendrogram

Considerations why 2 segments were used instead of 3:
* Size segments are smaller making analysis less effective
* Rolling out effective campaigns with 9 segments is more challenging

```{r}
plot(pop_segments$tree[[1]], main = "Dendrogram for AGYW")
abline(h = 300, col = "red")
```

### Cluster Visualisation

```{r}

silhoutte <- list()

for (pop in seq_along(pop_segments$data)){

silhoutte[[pop]] <- fviz_nbclust(
  x = data.frame(b_scores = pop_segments$data[[pop]]$b_score), 
  FUNcluster = hcut, 
  method = "silhouette")

silhoutte[[pop]] <-
silhoutte[[pop]] + 
  labs(title = glue::glue("Optimal number of clusters in {pop_segments$Population[[pop]]}"))
}


for (pop in 1:pop){
  print(silhoutte[[pop]])
}
```


```{r}

gap_stat <- list()

for (pop in seq_along(pop_segments$data)){

gap_stat[[pop]] <- fviz_nbclust(
  x = data.frame(b_scores = pop_segments$data[[pop]]$b_score), 
  FUNcluster = hcut, 
  method = "gap_stat", 
  nboot = 10)

gap_stat[[pop]] <-
gap_stat[[pop]] + 
  labs(title = glue::glue("Optimal number of clusters in {pop_segments$Population[[pop]]}"))
}


for (pop in 1:pop){
  print(gap_stat[[pop]])
}
```


## Comparision with previous segments

```{r}
data_pk %>% 
  select(Client_ID, previous_segment = Segment, Continuation_rates = Continuation_rates.x) %>% 
  left_join(segment_data, by = "Client_ID") %>% 
  rename(current_segment = segment) %>% 
  mutate(previous_segment = parse_number(previous_segment)) %>% 
  mutate(previous_segment = as.character(previous_segment)) %>% 
  group_by(population, previous_segment) %>% 
  mutate(previous_count = n()) %>% 
  group_by(population, current_segment) %>% 
  mutate(current_count = n()) %>% 
  group_by(population, Continuation_rates, previous_segment, current_segment) %>% 
  summarise(previous_count = mean(previous_count),
            current_count = mean(current_count)) %>% 
  ungroup() %>% 
  relocate(previous_count, .after = previous_segment) %>% 
  write_xlsx("../outputs/segment_comparison.xlsx")
```


```{r}
data_pk %>% 
  select(Client_ID, previous_segment = Segment, Continuation_rates = Continuation_rates.x) %>% 
  left_join(segment_data, by = "Client_ID") %>% 
  rename(current_segment = segment) %>% 
  mutate(previous_segment = parse_number(previous_segment)) %>% 
  mutate(previous_segment = as.character(previous_segment)) %>% 
  filter(str_detect(string = population, pattern = "FSW")) %>% 
  count(previous_segment, current_segment) %>% 
  filter(previous_segment %in% c(1, 4))
```


## SHAP values

**This approach was not used as the results were not easy to interpret especially for continuous variables.**

Useful for understanding the direction of influence of features

```{r}
data_train <- final_clean[,names(final_clean) %in% c(imp_vars_wrapper,"Continuation_rates")]
data_train <- cbind(data_train, b_score = data_raw$b_score/1000)

data_train_x <- data_train %>% select(-Continuation_rates, -b_score)

data_train_lo <- data_train %>% filter(Continuation_rates=="No.continuation") %>% select(-Continuation_rates, -b_score)

data_train_hi <- data_train %>% filter(Continuation_rates=="Continuation.3") %>% select(-Continuation_rates, -b_score)
```


```{r}
# :class: name of the class we are interested in. Leave blank to get all classes

shap_predictor <-
Predictor$new(model = model_rf_wr,
              data = data_train %>% select(-b_score),
              y = "Continuation_rates",
              class = c("No.continuation"),
              type = "prob")

shap_predictor
```


```{r}
system.time({

doParallel::registerDoParallel(cores = parallel::detectCores())

# shap_res_low <-
# Shapley$new(predictor = shap_predictor, 
#             x.interest = data_train_lo,
#             sample.size = 5)

shap_res_low <-
Shapley$new(predictor = shap_predictor, 
            x.interest = data_train_lo,
            sample.size = 50)

shap_res_high <-
Shapley$new(predictor = shap_predictor, 
            x.interest = data_train_hi,
            sample.size = 50)

doParallel::stopImplicitCluster()

})
```

What does Age=24 or Age=18 mean?

```{r}
library(patchwork)

plot_low <- plot(shap_res_low)
plot_high <- plot(shap_res_high)

plot_low
plot_high
```



```{r}
library(tidytext)

shap_res$results %>% 
  mutate(feature.value = reorder_within(feature.value, phi, class)) %>% 
  ggplot(aes(x = feature.value, y = abs(phi))) +
  geom_col() +
  coord_flip() +
  facet_wrap(~class, "free") +
  scale_x_reordered()
```

## PDP plots

### Variables list

Define a nested list of variables and their class.

```{r}
model_vars <-
final_clean %>% 
  select(all_of(imp_vars_wrapper)) %>% 
  summarise(across(.cols = everything(), .fns = class)) %>% 
  pivot_longer(cols = everything(),
               names_to = "variable",
               values_to = "class") %>% 
  mutate(vars = map2(.x = variable, .y = class, .f = list)) %>% 
  pull(vars)

length(model_vars)
```


```{r}
model_vars[1]

model_vars[[1]][1]

unlist(model_vars[[1]][2])

class(unlist(model_vars[[1]][2]))

unlist(model_vars[[1]][2])=="factor"
```

### Plotting function

This will return just one plot for a given to be stored in a list later.

```{r}
# model: a trained model
# continuation rate: a outcome in the outcome variable
# model vars: a nested list containing an independent variable and its class
# returns: a named list containing a single plot, its table, and continuation rate being observed

plot_pdp <- function(model, continuation_rate, model_vars){
  
  variable <- unlist(model_vars[[1]][1])
  class <- unlist(model_vars[[1]][2])
  
  if (class == "factor"){
    
    pdp_plot <-
    pdp::partial(object = {{ model }},
            pred.var = variable,
            which.class = continuation_rate,
            plot = FALSE,
            plot.engine = "ggplot2") %>%
    as_tibble() %>%
    mutate({{ variable}} := fct_reorder(.data[[variable]], yhat)) %>%
    ggplot(aes(x = .data[[variable]], y = yhat)) +
    geom_col() +
    coord_flip() +
    labs(title = glue::glue("PDP for {variable} on {continuation_rate}"),
         x = NULL)

  } else {

  pdp_plot <-
  pdp::partial(object = {{ model }},
          pred.var = variable,
          which.class = continuation_rate,
          plot = TRUE,
          plot.engine = "ggplot2") +
  geom_smooth(method = "loess", se = TRUE, formula = y ~ x) +
  labs(title = glue::glue("PDP for {variable} on {continuation_rate}"))

  }
  
  pdp_tbl <-
    pdp::partial(object = {{ model }},
            pred.var = variable,
            which.class = continuation_rate,
            plot = FALSE,
            plot.engine = "ggplot2") %>%
    as_tibble() %>% 
    mutate({{ variable}} := as.character(.data[[variable]]))


  pdp_plots <- list(plt = pdp_plot,
                    tbl = pdp_tbl,
                    rate = continuation_rate)
  
  return(pdp_plots)
}
```


```{r}
pdp_plots <- plot_pdp(model = model_rf_wr, continuation_rate = "No.continuation", model_vars = model_vars[2])

pdp_plots$plt

pdp_plots$tbl

pdp_plots$rate
```


### Obtain PDP results

This will take the returned named list and store it in a list.

```{r}
doParallel::registerDoParallel(cores = 2)

pdp_res <- list()

for (var in seq_along(model_vars)){
pdp_res[[var]] <- plot_pdp(model = model_rf_wr,
                           continuation_rate = "No.continuation",
                           model_vars = model_vars[var])
}

doParallel::stopImplicitCluster()

length(pdp_res)
```


### Print plots

Iterate over the list of results and print each plot.

```{r}
doParallel::registerDoParallel(cores = parallel::detectCores())

for (res in seq_along(pdp_res)){
  suppressWarnings(print(pdp_res[[res]]$plt))
}

doParallel::stopImplicitCluster()
```


### Print both tables and plots

```{r}
doParallel::registerDoParallel(cores = parallel::detectCores())

for (res in seq_along(pdp_res[1:2])){
  suppressWarnings(print(pdp_res[[res]]))
}

doParallel::stopImplicitCluster()
```


### Concatenated tables

```{r}
pdp_tbls <- tibble(.rows = 0)

for (var in seq_along(pdp_res)){
  pdp_df <- 
    pdp_res[[var]]$tbl %>% 
    mutate(variable = colnames(.)[1]) %>% 
    mutate(rate = pdp_res[[var]]$rate) %>% 
    setNames(object = ., nm = c("response","yhat","variable","continuation_rate"))
  
  pdp_tbls <- rbind(pdp_tbls, pdp_df)
}

pdp_tbls
#write_xlsx(pdp_tbls,"../outputs/pdp_res_tbl_no.xlsx")
```


## Sense checks

* Older people are in Continuation 3, younger people in Continuation 1
* People in Migori & Nyamari are likely to be in No continuation category

```{r}
data_train %>% 
  group_by(Continuation_rates) %>% 
  summarise(age = mean(clean_age))

data_train %>% 
  group_by(Continuation_rates, Clinic) %>% 
  summarise(n = n()) %>%
  arrange(Continuation_rates, desc(n))
```


# SUMMARY STATISTICS

## Demographic variables 

These are summary statistics of the socio-demographic features of the survey participants.

`e1demoq9` is the respondent's name.

```{r}
demo_vars <- 
  data_labeled %>% 
  select(Population, contains(c("demo","hse"))) %>% 
  select(-e1demoq9) %>% 
  drop_var_labs()

colnames(demo_vars)
demo_vars
```

### Outcome

```{r}
pop_outcome <-
data_labeled %>%
  group_by(Population) %>% 
  count(Continuation_rates) %>% 
  mutate(prop = n/sum(n),
         perc = percent(x = prop, accuracy = 0.1)) %>% 
  mutate(freq_perc = glue("{n} ({perc})")) %>% 
  select(-n, -prop, -perc) %>% 
  pivot_wider(names_from = Population,
              values_from = freq_perc)

overall_outcome <-
data_labeled %>% 
  count(Continuation_rates) %>% 
  mutate(prop = n/sum(n),
         perc = percent(x = prop, accuracy = 0.1)) %>%
  mutate(Overall = glue("{n} ({perc})")) %>% 
  select(-n, -prop, -perc)

demo_outcome <-
pop_outcome %>% 
  left_join(overall_outcome) %>% 
  rename(variable = Continuation_rates) %>% 
  mutate(category = "Frequency (Percentage)") %>% 
  relocate(category, .after = variable)

demo_outcome
```

### Numeric

Demographic variables as listed in the survey instrument.

```{r}
pop_numeric <-
  demo_vars %>% 
  select(Population, is.numeric) %>% 
  group_by(Population) %>% 
  summarise(across(.fns = list(mean = ~mean(x = ., na.rm = TRUE),
                               sd = ~sd(x = ., na.rm = TRUE),
                               median = ~median(x = ., na.rm = TRUE)))) %>% 
  pivot_longer(cols = -Population) %>% 
  extract(col = name, 
          into = c("variable","metric"), 
          regex = "(.*)_(.*)", 
          remove = TRUE) %>% 
  pivot_wider(names_from = metric,
              values_from = value) %>% 
  mutate(mean = round(mean, ROUND),
         sd = round(sd, ROUND)) %>% 
  mutate(mean_sd = glue("{mean} ({sd})")) %>% 
  select(-mean, -sd, -median) %>% 
  pivot_wider(names_from = Population,
              values_from = mean_sd)

overall_numeric <-
demo_vars %>% 
  select(is.numeric) %>% 
  summarise(across(.fns = list(mean = ~mean(x = ., na.rm = TRUE),
                               sd = ~sd(x = ., na.rm = TRUE)))) %>% 
  pivot_longer(cols = everything()) %>% 
  extract(col = name, 
          into = c("variable","metric"), 
          regex = "(.*)_(.*)", 
          remove = TRUE) %>% 
  pivot_wider(names_from = metric,
              values_from = value) %>% 
  mutate(mean = round(mean, ROUND),
         sd = round(sd, ROUND)) %>% 
  mutate(Overall = glue("{mean} ({sd})")) %>% 
  select(-mean, -sd)

demo_numeric <-
pop_numeric %>% 
  left_join(overall_numeric, by = "variable") %>% 
  mutate(category = "Mean +/- SD") %>% 
  relocate(category, .after = variable)

demo_numeric
```

### Categorical

Logical data types represent null columns.

```{r}
demo_vars %>% 
  summarise(across(.fns = class)) %>% 
  pivot_longer(cols = everything()) %>% 
  filter(value=="logical")


demo_vars %>% 
  count(e1end11e2hseq34_5)
```


```{r}
demo_vars_cat <-
  demo_vars %>% 
  select(where(is.character)) %>% 
  select(-Population) %>% 
  colnames()

demo_vars_cat
```

```{r}
data_labeled %>% 
  count(Population, response = e1demoend1q15)
```

```{r}
demo_categorical <- tibble(.rows = 0)

for (var in seq_along(demo_vars_cat)){
  demo_df <-
    data_labeled %>% 
    count(Population, response = .data[[demo_vars_cat[var]]]) %>%
    mutate(variable = demo_vars_cat[var])
  
  demo_categorical <- rbind(demo_categorical, demo_df)
  demo_categorical <- drop_var_labs(demo_categorical)
}
```


```{r}
pop_categorical <-
demo_categorical %>%
  group_by(Population, variable) %>% 
  mutate(prop = n/sum(n),
         perc = percent(x = prop, accuracy = 0.1)) %>% 
  mutate(freq_perc = glue("{n} ({perc})")) %>% 
  arrange(desc(n), .by_group = TRUE) %>% 
  select(-n, -prop, -perc) %>% 
  relocate(variable, .after = Population) %>% 
  pivot_wider(names_from = Population,
              values_from = freq_perc)

pop_categorical
```


```{r}
overall_categorical <-
demo_categorical %>% 
  pivot_wider(names_from = Population,
              values_from = n,
              values_fill = 0) %>% 
  mutate(total = rowSums(across(AGYWs:MSMs))) %>% 
  mutate(prop = total/nrow(data_raw),
         perc = percent(x = prop, accuracy = 0.1)) %>% 
  mutate(Overall = glue("{total} ({perc})")) %>% 
  select(variable, response, Overall)

overall_categorical
```


```{r}
demo_categorical_summ <-
pop_categorical %>% 
  left_join(overall_categorical) %>% 
  rename(category = response)

demo_categorical_summ
```


### Null values

```{r}
demo_nulls <-
  demo_vars %>% 
  group_by(Population) %>% 
  summarise(across(.cols = everything(),
                   .fns = ~sum(is.na(.)))) %>% 
  pivot_longer(cols = -Population,
               names_to = "variable",
               values_to = "nulls") %>% 
  pivot_wider(names_from = Population,
              values_from = nulls) %>% 
  mutate(Overall = rowSums(across(AGYWs:MSMs)))

few_nulls <-
demo_nulls %>% 
  arrange(Overall) %>% 
  filter(Overall < 100) %>% 
  pull(variable)

few_nulls
```

### Variable levels

Number of choices for categorical responses.

```{r}
few_levels <-
left_join(
demo_vars %>% 
  select(all_of(demo_vars_cat)) %>%
  summarise(across(.cols = everything(),
                   .fns = list(len = ~length(unique(.)),
                               vals = ~paste0(unique(.), collapse = ",")))) %>% 
  pivot_longer(cols = contains("len"),
               values_to = "lens") %>% 
  select(name, lens) %>% 
  mutate(name = str_remove(string = name, pattern = "_len")),


demo_vars %>% 
  select(all_of(demo_vars_cat)) %>%
  summarise(across(.cols = everything(),
                   .fns = list(len = ~length(unique(.)),
                               vals = ~paste0(unique(.), collapse = ",")))) %>% 
  pivot_longer(cols = contains("vals"),
               values_to = "vals") %>% 
  select(name, vals) %>% 
  mutate(name = str_remove(string = name, pattern = "_vals")), 

by = "name") %>% 
  arrange(desc(lens)) %>% 
  filter(lens <= 5)

few_levels
```

### Appending

```{r}
socio_demographic_stats <-
demo_numeric %>% 
  bind_rows(demo_categorical_summ) %>% 
  left_join(data_dictionary, by = "variable") %>% 
  select(-value, -meta) %>% 
  relocate(label, .after = variable) %>% 
  mutate(sorter = str_extract(string = Overall, pattern = "^\\d+")) %>%
  mutate(sorter = parse_number(sorter)) %>% 
  arrange(variable, desc(sorter)) %>% 
  select(-sorter)

socio_demographic_stats
#write_xlsx(x = socio_demographic_stats, path = "../outputs/socio_demographic_stats.xlsx")
```

### For discussion

These are variables with reasonably few levels and null values, as well as numeric variables.

```{r}
demo_for_discussion <-
append(
few_levels %>% 
  filter(name %in% few_nulls) %>% 
  pull(name),

demo_numeric %>% 
  pull(variable))

demo_for_discussion
```

Remove percent sign.

```{r}
socio_demographic_stats %>% 
  filter(variable %in% demo_for_discussion) %>% 
  write_xlsx(path = "../outputs/for_discussion.xlsx")

  map_df(.x = ., 
         .at = c("AGYWs","FSWs","MSMs"), 
         .f = ~gsub(x = ., pattern = "%", replacement = "")) %>% 
  write_xlsx(path = "../outputs/for_discussion.xlsx")
```


```{r}
data_labeled %>% 
  count(Population)
```


## Important variables

These are summary statistics for the 28 most important variables.

### Categorical variables

Counts of responses per segment.

```{r}
cat_cols <- 
data_labeled %>% 
  select(all_of(imp_vars_wrapper)) %>% 
  select(where(is_character)) %>% 
  colnames()

cat_cols
```


```{r}
count_df <- tibble(.rows = 0)

for (col in seq_along(cat_cols)){
df <-
  data_labeled %>% 
  group_by(Population) %>% 
  count(category = .data[[cat_cols[col]]], name = "frequency") %>% 
  mutate(variable = cat_cols[col])

count_df <- rbind(count_df, df)
}

count_df
```

```{r}
imp_pop_categorical <-
count_df %>% 
  relocate(variable, .before = everything()) %>% 
  group_by(Population) %>% 
  mutate(count = case_when(Population == "AGYWs" ~ 198,
                           Population == "FSWs" ~ 200,
                           TRUE ~ 199)) %>% 
  mutate(prop = frequency / count,
         perc = percent(x = prop, accuracy = 0.1)) %>% 
  mutate(freq_perc = glue("{frequency} ({perc})")) %>% 
  select(-count, -prop, -frequency, -perc) %>% 
  pivot_wider(names_from = Population,
              values_from = freq_perc)

imp_pop_categorical
```

```{r}
imp_overall_categorical <-
count_df %>% 
  ungroup() %>% 
  pivot_wider(names_from = Population,
              values_from = frequency,
              values_fill = 0) %>% 
  mutate(Overall = rowSums(across(AGYWs:MSMs))) %>% 
  mutate(prop = Overall/597,
         perc = percent(x = prop, accuracy = 0.1),
         freq_perc = glue("{Overall} ({perc})")) %>% 
  select(variable, category, Overall = freq_perc, prop)

imp_overall_categorical
```

```{r}
imp_categorical <-
imp_pop_categorical %>% 
  left_join(imp_overall_categorical) %>% 
  arrange(variable, desc(prop)) %>% 
  select(-prop)

imp_categorical
```

### Numeric varibles

Mean and median values

```{r}
means_df <-
data_labeled %>% 
  select(all_of(imp_vars_wrapper)) %>% 
  select(where(is.numeric)) %>% 
  bind_cols(Population = data_labeled$Population) %>% 
  group_by(Population) %>% 
  summarise(across(.cols = everything(), 
                   .fns = list(mean = mean, 
                               sd = sd))) %>% 
  pivot_longer(cols = -Population) %>% 
  extract(col = name, 
          into = c("variable","metric"), 
          regex = "(.*)_(.*)", 
          remove = TRUE) %>% 
  pivot_wider(names_from = metric,
              values_from = value) %>% 
  mutate(mean = round(mean, ROUND),
         sd = round(sd, ROUND))

means_df
```

```{r}
imp_pop_numerical <-
means_df %>% 
  mutate(mean_sd = glue("{mean} ({sd})")) %>% 
  mutate(category = "Mean +/- SD") %>% 
  select(-mean, -sd) %>% 
  pivot_wider(names_from = Population,
              values_from = mean_sd)

imp_pop_numerical
```

```{r}
imp_overall_numeric <-
data_labeled %>% 
  select(all_of(imp_vars_wrapper)) %>% 
  select(where(is.numeric)) %>% 
  summarise(across(.fns = list(mean = mean,
                               sd = sd))) %>% 
  pivot_longer(cols = everything()) %>% 
  extract(col = name, 
          into = c("variable","metric"), 
          regex = "(.*)_(.*)", 
          remove = TRUE) %>% 
  pivot_wider(names_from = metric,
              values_from = value) %>% 
  mutate(mean = round(mean, ROUND),
         sd = round(sd, ROUND)) %>% 
  mutate(mean_sd = glue("{mean} ({sd})")) %>% 
  select(variable, Overall = mean_sd)

imp_overall_numeric
```

```{r}
imp_numerical <-
imp_pop_numerical %>% 
  left_join(imp_overall_numeric)

imp_numerical
```


```{r}
imp_vars_desc <-
imp_categorical %>% 
  drop_var_labs() %>% 
  bind_rows(imp_numerical) %>% 
  left_join(data_dictionary, by = "variable") %>% 
  select(-value, -meta)

imp_vars_desc
#write_xlsx(x = imp_vars_desc, path = "../outputs/imp_vars_desc.xlsx")
```

```{r}
imp_vars_desc %>% 
  filter(variable %in% imp_vars_wrapper[1:10]) %>% 
  write_xlsx("../outputs/top_10_imp.xlsx")
```


```{r}
data_raw %>% 
  mutate(Continuation_rates = factor(Continuation_rates)) %>% 
  mutate(Continuation_rates = relevel(x = Continuation_rates, ref = "No continuation")) %>% 
  ggplot(aes(Continuation_rates)) +
  geom_histogram(stat = "count")
```

# PERSONAS

## Persona data

This will be used for Power BI dashboards.

```{r}
data_labeled %>% 
  select(-b_score, -b_group, -b_segment) %>% 
  drop_var_labs() %>% 
  left_join(segment_data, by = "Client_ID") %>% 
  select(-population) %>% 
  write_xlsx("../outputs/persona_data.xlsx")
```

## Summary stats

Summary statistics for the personas (socio-demographic characteristics and most important variables)

```{r}
personas_desc <-
data_labeled %>% 
  select(-b_score, -b_group, -b_segment) %>% 
  drop_var_labs() %>% 
  left_join(segment_data, by = "Client_ID") %>% 
  select(-population) %>% 
  select(all_of(c(colnames(demo_vars),imp_vars_wrapper,"b_score", "segment")))

# Select only numeric and character columns and group our data appropriately
personas_proc <- 
  personas_desc %>% 
  select(-where(is.logical)) %>% 
  group_by(Population, segment)

personas_proc
```

```{r}
personas_proc %>%
  summarise(across(.cols = is.numeric, 
                   .fns = list(mean = ~mean(x = ., na.rm = TRUE),
                               sd = ~sd(x = ., na.rm = TRUE))))

personas_proc %>% 
  count(personas_proc[[57]]) %>% 
  mutate(variable = colnames(personas_proc)[57])
```
Categorical variables

```{r}
persona_cat <- tibble(.rows = 0)

for (var in seq_along(colnames(personas_proc))){
  
  if (class(personas_proc[[var]]) == "character"){
    
    persona_df <-
    personas_proc %>% 
      count(personas_proc[[var]]) %>% 
      mutate(variable = colnames(personas_proc[var])) %>% 
      set_names(c("Population", "segment", "category", "Freq", "variable"))
    
    persona_cat <- bind_rows(persona_cat, persona_df)
    
  } 
}

persona_cat
```
Numeric variables.

```{r}
persona_tbl <-
personas_proc %>%
  summarise(across(.cols = is.numeric, 
                   .fns = list(mean = ~mean(x = ., na.rm = TRUE),
                               sd = ~sd(x = ., na.rm = TRUE)))) %>% 
  pivot_longer(cols = c(-Population, -segment)) %>% 
  extract(col = name, 
          into = c("variable", "metric"), 
          regex = "(.*)_(.*)", 
          remove = TRUE, 
          convert = TRUE) %>% 
  pivot_wider(names_from = metric,
              values_from = value) %>% 
  mutate(across(.cols = c(mean, sd), .fns = ~round(x = ., digits = ROUND))) %>% 
  mutate(category = "Mean +/- SD") %>% 
  bind_rows(persona_cat)

persona_tbl
```

```{r}
personas_sizes <-
personas_proc %>% 
  select(Population, segment) %>% 
  count(segment)

personas_sizes
```

Formatted table.

```{r}
persona_stats <-
persona_tbl %>% 
  left_join(personas_sizes, by = c("Population","segment")) %>% 
  left_join(data_dictionary_updated, by = "variable") %>% 
  mutate(prop = Freq/n,
         perc = percent(x = prop, accuracy = 0.1),
         freq_perc = glue("{Freq} ({perc})"),
         freq_perc = na_if(x = freq_perc, y = "NA (NA)")) %>% 
  mutate(mean_sd = glue("{mean} ({sd})")) %>% 
  mutate(stat = coalesce(freq_perc, mean_sd)) %>% 
  select(Population, segment, category, variable, stat, label) %>% 
  pivot_wider(names_from = segment,
              values_from = stat) %>% 
  arrange(Population, variable) %>% 
  relocate(label, .after = everything())

persona_stats
#write_xlsx(x = persona_stats, path = "../outputs/persona_stats.xlsx")
```


```{r}
persona_analysed <-
read_excel(path = "../outputs/persona_stats.xlsx", 
           sheet = "Sheet2") %>% 
  select(variable, type) %>% 
  filter(!is.na(type))

persona_discussed <-
persona_stats %>% 
  left_join(persona_analysed, by = "variable") %>% 
  filter(!is.na(type)) %>% 
  select(Population, variable, type, category, "1", "2", label) %>% 
  arrange(Population, type, variable)

persona_discussed
#write_xlsx(x = persona_discussed, path = "../outputs/persona_discussed.xlsx")
```

# EXPORT

```{r}
save.image("../outputs/22Aug.RData")
```


```{r}
rm(list = ls())

load("../outputs/12Aug.RData")
```


